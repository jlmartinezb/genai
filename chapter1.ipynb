{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db1d4338",
   "metadata": {},
   "source": [
    "### Practical Exercises and Code Examples\n",
    "\n",
    "This chapter includes several code examples and practical exercises to help you apply the concepts discussed. You can find these examples in the accompanying Jupyter Notebook: `chapter1.ipynb`.\n",
    "\n",
    "The notebook contains:\n",
    "- Step-by-step implementation of LangChain and Perplexity examples.\n",
    "- Exercises to experiment with temperature, prompt design, and structured outputs.\n",
    "- Additional code snippets to explore metadata and integrate external data sources.\n",
    "\n",
    "Make sure to open the notebook in Jupyter or VS Code to follow along and execute the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd310a1",
   "metadata": {},
   "source": [
    "#### 1. Set Up Your Environment\n",
    "- Use the `install_package` function provided in the notebook to ensure all required libraries (`langchain_core`, `langchain_perplexity`, and `dotenv`) are installed in your environment.\n",
    "- Verify that your `.env` file contains the `PERPLEXITY_API_KEY`. If not, create one and set the key.\n",
    "\n",
    "You need to activate an API key to use the Perplexity API. This must be done from the Perplexity website. Once you obtain the API key, you can set it directly in the notebook using the following line of code api_key in the ChatPerplexity(api_key=\"api_key\",....) command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55de917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        print(f\"{package} is not installed. Installing...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "install_package(\"langchain_core\")\n",
    "install_package(\"langchain_perplexity\")\n",
    "install_package(\"dotenv\")\n",
    "\n",
    "# Import required libraries\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_perplexity import ChatPerplexity\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the API key from the .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"Perplexity API key not found. Make sure to set it in the .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56874efc",
   "metadata": {},
   "source": [
    "## 2. Experiment with Temperature\n",
    "- Modify the `temperature` parameter in the `ChatPerplexity` model initialization (e.g., 0.2, 0.5, 0.9).\n",
    "- Observe how the model's responses change with different temperature values. Which setting produces the most deterministic response? Which one is more creative?\n",
    "\n",
    "Subsequently, you can select the Perplexity model to use in the notebook using the following command ChatPerplexity(model=\"sonar\") where you can change the model to whichever model you want to use. The models are available on the Perplexity website: https://docs.perplexity.ai/models/model-cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f5d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Perplexity model\n",
    "model = ChatPerplexity(api_key=api_key, model=\"sonar\", temperature=0.9)\n",
    "model.invoke(\"WhatÂ´s the capital of Spain?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e00793",
   "metadata": {},
   "source": [
    "### 3. Custom Prompt Design\n",
    "- Create a custom prompt using `SystemMessage` and `HumanMessage` to guide the model's behavior.\n",
    "- For example, define a `SystemMessage` that sets the model as an expert in a specific domain (e.g., \"You are an expert in embedded systems.\") and ask a relevant question using `HumanMessage`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6966847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_perplexity import ChatPerplexity\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "model = ChatPerplexity(api_key=api_key,\n",
    "           model=\"sonar\",\n",
    "           temperature=0.9)\n",
    "system_msg = SystemMessage(content=\n",
    "                           '''You are a helpful assistant. That are expert in Electonic and embeded System.''')\n",
    "user_msg = HumanMessage(content='''What is a esp32 microcontroller?''')\n",
    "\n",
    "messages = [system_msg, user_msg]\n",
    "model.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6e2f9e",
   "metadata": {},
   "source": [
    "### 4. Prompt Reuse with Templates\n",
    "- Use the `ChatPromptTemplate` class to create a reusable prompt template.\n",
    "- Define placeholder variables (e.g., `{context}` and `{question}`) and test the template with different inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12dbc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserved space to include the previous prompt text with context\n",
    "# You can copy and paste here the context you want to use in the prompt\n",
    "\n",
    "context = \"\"\"\n",
    "[Include here the context text you want to use in the prompt]\n",
    "\"\"\"\n",
    "\n",
    "# Example usage with the template and the model\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the following question using ONLY the provided text. If you don't know the answer, say you don't know.\"),\n",
    "    (\"human\", \"context: {context}\\nquestion: {question}\")\n",
    "])\n",
    "\n",
    "question = \"Is it capable of using MQTT?\"\n",
    "\n",
    "prompt_instance = prompt_template.invoke({\n",
    "    \"context\": context,\n",
    "    \"question\": question\n",
    "})\n",
    "\n",
    "response = model.invoke(prompt_instance)\n",
    "print(\"Model response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76930270",
   "metadata": {},
   "source": [
    "### 5. Structured Output\n",
    "- Implement the `answerWithJustificaction` class using `Pydantic` as shown in the notebook.\n",
    "- Use the `with_structured_output` method to ensure the model returns responses in a structured format.\n",
    "- Test the model with a question and inspect the JSON output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba177b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from langchain_perplexity import ChatPerplexity\n",
    "\n",
    "class answerWithJustificaction(BaseModel):\n",
    "    answer: str\n",
    "    justification: str\n",
    "\n",
    "llm = ChatPerplexity(api_key=api_key,\n",
    "                       model=\"sonar\",\n",
    "                       temperature=0.9)\n",
    "\n",
    "structuredLLM = llm.with_structured_output(answerWithJustificaction)\n",
    "\n",
    "result =structuredLLM.invoke(\"How many people live in New York City?\")\n",
    "result.model_dump_json(indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ee6a9f",
   "metadata": {},
   "source": [
    "### 6. Explore Metadata\n",
    "- Invoke the `ChatPerplexity` model with a query and inspect the `metadata` field in the response.\n",
    "- Identify the `model_name`, `id`, and `usage_metadata` fields. How can this information be useful for optimizing your application?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332d08ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using Perplexity API with custom prompt and structured output\n",
    "\n",
    "# Create a custom system message to set the assistant's expertise\n",
    "system_msg = SystemMessage(content=\"You are an expert in embedded systems and electronics.\")\n",
    "\n",
    "# Create a human message with a relevant question\n",
    "user_msg = HumanMessage(content=\"What is an ESP32 microcontroller?\")\n",
    "\n",
    "# Combine messages into a list\n",
    "messages = [system_msg, user_msg]\n",
    "\n",
    "# Invoke the model with the custom prompt\n",
    "response = model.invoke(messages)\n",
    "print(\"Model response:\")\n",
    "print(response)\n",
    "\n",
    "# Define a structured output class using Pydantic\n",
    "class AnswerWithJustification(BaseModel):\n",
    "    answer: str\n",
    "    justification: str\n",
    "\n",
    "# Create a structured LLM using the Perplexity model\n",
    "structured_llm = model.with_structured_output(AnswerWithJustification)\n",
    "\n",
    "# Ask a question and get a structured response\n",
    "structured_response = structured_llm.invoke(\"Is ESP32 suitable for IoT applications?\")\n",
    "print(\"Structured response (JSON):\")\n",
    "print(structured_response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6277f51b",
   "metadata": {},
   "source": [
    "These exercises are designed to help you apply the concepts discussed in this chapter and gain hands-on experience with LangChain and Perplexity. Feel free to experiment and adapt the examples to your specific use cases. In the next chapter, we will build on these foundations to explore more advanced techniques and workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
